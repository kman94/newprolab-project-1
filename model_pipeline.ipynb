{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cf441890834cefbaf86154c0d97df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/data/share/project01/gender_age_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = None #100\n",
    "df = pd.read_csv(file_path, sep='\\t', nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>user_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>d50192e5-c44e-4ae8-ae7a-7cfe67c8b777</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502331d-621e-4721-ada2-5d30b2c3801f</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d50237ea-747e-48a2-ba46-d08e71dddfdb</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502f29f-d57a-46bf-8703-1cb5f8dcdf03</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://translate-tattoo.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>d503c3b2-a0c2-4f47-bb27-065058c73008</td>\n",
       "      <td>{\"visits\": [{\"url\": \"https://mail.rambler.ru/#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                   uid  \\\n",
       "0      F  18-24  d50192e5-c44e-4ae8-ae7a-7cfe67c8b777   \n",
       "1      M  25-34  d502331d-621e-4721-ada2-5d30b2c3801f   \n",
       "2      F  25-34  d50237ea-747e-48a2-ba46-d08e71dddfdb   \n",
       "3      F  25-34  d502f29f-d57a-46bf-8703-1cb5f8dcdf03   \n",
       "4      M   >=55  d503c3b2-a0c2-4f47-bb27-065058c73008   \n",
       "\n",
       "                                           user_json  \n",
       "0  {\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...  \n",
       "1  {\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...  \n",
       "2  {\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...  \n",
       "3  {\"visits\": [{\"url\": \"http://translate-tattoo.r...  \n",
       "4  {\"visits\": [{\"url\": \"https://mail.rambler.ru/#...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убеждаемся, что целевые переменные либо одновременно заполнены, либо одновременно пусты\n",
    "assert len(df.loc[(df['age'] == '-') & (df['gender'] != '-')]) == 0\n",
    "assert len(df.loc[(df['gender'] == '-') & (df['age'] != '-')]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделяем данные для обучения\n",
    "df = df.loc[(df['age'] != '-') & (df['gender'] != '-')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.request import urlretrieve, unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractDomainTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Добавляет столбец со списком доменов.\"\"\"        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X['user_json'].progress_apply(lambda x: [self.url2domain(el['url']) for el in json.loads(x)['visits']])\n",
    "    \n",
    "    @staticmethod\n",
    "    def url2domain(url):\n",
    "        url = re.sub('(http(s)*://)+', 'http://', url)\n",
    "        parsed_url = urlparse(unquote(url.strip()))\n",
    "        if parsed_url.scheme not in ['http','https']: return None\n",
    "        netloc = re.search(\"(?:www\\.)?(.*)\", parsed_url.netloc).group(1)\n",
    "        if netloc is not None: return netloc.strip()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToFloatTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Приводит элементы матрицы признаков к типу float64.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = enc.fit_transform(df[['gender', 'age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['F', 'M'], dtype=object),\n",
       " array(['18-24', '25-34', '35-44', '45-54', '>=55'], dtype=object)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем данные на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoOutputClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"Классификатор, предсказывающий две целевые переменные \n",
    "       с использованием базовых классификаторов.\"\"\"\n",
    "    def __init__(self, first_classifier, second_classifier, top50=True):\n",
    "        self.first_classifier = first_classifier\n",
    "        self.second_classifier = second_classifier\n",
    "        self.top50 = top50\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.first_classifier.fit(X, y[:,0])\n",
    "        self.second_classifier.fit(X, y[:,1])\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.top50:\n",
    "            probas1, probas2 = self.predict_proba(X)\n",
    "            y_pred = self.predict_by_proba(self.select_top50(probas1, probas2))\n",
    "            return np.array([el[0] for el in y_pred]), np.array([el[1:] for el in y_pred])\n",
    "        else:\n",
    "            return np.stack([self.first_classifier.predict(X), self.second_classifier.predict(X)], axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return [self.first_classifier.predict_proba(X), self.second_classifier.predict_proba(X)]\n",
    "    \n",
    "    def select_top50(self, probas1, probas2):\n",
    "        index_probas_list = list(zip(range(len(probas1)), probas1, probas2))\n",
    "        index_probas_list.sort(key=lambda x: max(x[1]) * max(x[2]), reverse=True)\n",
    "        return index_probas_list[:(len(index_probas_list) + 1) // 2]\n",
    "    \n",
    "    def predict_by_proba(self, index_probas_list):\n",
    "        return [(x[0], x[1].argmax(), x[2].argmax()) for x in index_probas_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDomainsAndContents:\n",
    "    def __init__(self):\n",
    "        self.domain_labels = pickle.load(open('data/domain_labels.pickle', 'rb'))\n",
    "        \n",
    "    def __call__(self, user_domains):\n",
    "        return user_domains + ['category_{}'.format(self.domain_labels[domain]) for domain in user_domains if self.domain_labels.get(domain, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('extract_domain', ExtractDomainTransformer()),\n",
    "                     ('count_domain', CountVectorizer(analyzer=GetDomainsAndContents())),\n",
    "                     ('to_float', ToFloatTransformer()),\n",
    "                     ('clf', TwoOutputClassifier(LGBMClassifier(verbose=2), \n",
    "                                                 LGBMClassifier(verbose=2), top50=True))],\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c281f9933b4607a7745926ed5d7f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27103), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pipeline] .... (step 1 of 4) Processing extract_domain, total=  57.7s\n",
      "[Pipeline] ...... (step 2 of 4) Processing count_domain, total=   4.1s\n",
      "[Pipeline] .......... (step 3 of 4) Processing to_float, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  25.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('extract_domain', ExtractDomainTransformer()),\n",
       "                ('count_domain',\n",
       "                 CountVectorizer(analyzer=<__main__.GetDomainsAndContents object at 0x7f41317b6160>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=N...\n",
       "                                     second_classifier=LGBMClassifier(boosting_type='gbdt',\n",
       "                                                                      class_weight=None,\n",
       "                                                                      colsample_bytree=1.0,\n",
       "                                                                      learning_rate=0.1,\n",
       "                                                                      max_depth=-1,\n",
       "                                                                      min_child_samples=20,\n",
       "                                                                      min_child_weight=0.001,\n",
       "                                                                      min_split_gain=0.0,\n",
       "                                                                      n_estimators=100,\n",
       "                                                                      n_jobs=-1,\n",
       "                                                                      num_leaves=31,\n",
       "                                                                      objective=None,\n",
       "                                                                      random_state=None,\n",
       "                                                                      reg_alpha=0.0,\n",
       "                                                                      reg_lambda=0.0,\n",
       "                                                                      silent=True,\n",
       "                                                                      subsample=1.0,\n",
       "                                                                      subsample_for_bin=200000,\n",
       "                                                                      subsample_freq=0,\n",
       "                                                                      verbose=2),\n",
       "                                     top50=True))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_3',\n",
       " 'category_18',\n",
       " 'category_10',\n",
       " 'category_8',\n",
       " 'category_23',\n",
       " 'category_7',\n",
       " 'category_11',\n",
       " 'category_4',\n",
       " 'category_6',\n",
       " 'category_21',\n",
       " 'category_12',\n",
       " 'category_2',\n",
       " 'category_22',\n",
       " 'category_9',\n",
       " 'category_16',\n",
       " 'category_5',\n",
       " 'category_19',\n",
       " 'category_14',\n",
       " 'category_20',\n",
       " 'category_24',\n",
       " 'category_15',\n",
       " 'category_13',\n",
       " 'category_1',\n",
       " 'category_17',\n",
       " 'category.alldatasheet.com']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key in pipeline.named_steps['count_domain'].vocabulary_ if key.startswith('category')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка предсказательной способности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67ba3a416554734ba02de2f821029c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9035), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# предсказываем целевую переменную\n",
    "indices_pred, y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4038, 5030, 4848, ..., 2153, 7972, 4036]), array([[1, 2],\n",
       "        [1, 1],\n",
       "        [0, 2],\n",
       "        ...,\n",
       "        [0, 2],\n",
       "        [1, 2],\n",
       "        [0, 1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_pred, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем долю полностью совпадающих строк матриц y_true и y_pred\n",
    "def full_accuracy(y_true, y_pred):\n",
    "    return sum(np.logical_and(y_test[:,0] == y_pred[:,0], y_test[:,1] == y_pred[:,1])) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[indices_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [1., 0.],\n",
       "       [0., 2.],\n",
       "       ...,\n",
       "       [0., 2.],\n",
       "       [1., 2.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 1],\n",
       "       [0, 2],\n",
       "       ...,\n",
       "       [0, 2],\n",
       "       [1, 2],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3621071270473661"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05370156a3f64814b3488ac07ee13bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36138), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pipeline] .... (step 1 of 4) Processing extract_domain, total= 1.3min\n",
      "[Pipeline] ...... (step 2 of 4) Processing count_domain, total=   5.5s\n",
      "[Pipeline] .......... (step 3 of 4) Processing to_float, total=   0.0s\n",
      "[Pipeline] ............... (step 4 of 4) Processing clf, total=  22.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('extract_domain', ExtractDomainTransformer()),\n",
       "                ('count_domain',\n",
       "                 CountVectorizer(analyzer=<__main__.GetDomainsAndContents object at 0x7f40a1af81d0>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=N...\n",
       "                                     second_classifier=LGBMClassifier(boosting_type='gbdt',\n",
       "                                                                      class_weight=None,\n",
       "                                                                      colsample_bytree=1.0,\n",
       "                                                                      learning_rate=0.1,\n",
       "                                                                      max_depth=-1,\n",
       "                                                                      min_child_samples=20,\n",
       "                                                                      min_child_weight=0.001,\n",
       "                                                                      min_split_gain=0.0,\n",
       "                                                                      n_estimators=100,\n",
       "                                                                      n_jobs=-1,\n",
       "                                                                      num_leaves=31,\n",
       "                                                                      objective=None,\n",
       "                                                                      random_state=None,\n",
       "                                                                      reg_alpha=0.0,\n",
       "                                                                      reg_lambda=0.0,\n",
       "                                                                      silent=True,\n",
       "                                                                      subsample=1.0,\n",
       "                                                                      subsample_for_bin=200000,\n",
       "                                                                      subsample_freq=0,\n",
       "                                                                      verbose=2),\n",
       "                                     top50=True))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump([pipeline, enc], open('model.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
